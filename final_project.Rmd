---
title: "final_project"
author: Student 1 & Student 2
output: pdf_document
date: "2024-12-01"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
public_data <- read.csv('./data/NA_HQ_public_data.csv')
svi_data <- read.csv('./data/SVI2018_US.csv')
us_cities <- read.csv('./data/uscities.csv')
library(pander)
```

# 0. Contribution Statement

## Student 1

Student 1 mostly worked on questions ...

## Student 2

Student 2 mostly worked on questions ...

\pagenumbering{arabic}

# Introduction

Cities provide a glimpse into the local population of an area and are reflective of the culture and lifestyles in the region in which they are located. However, not all cities are created equal, as different socieoeconomic factors within the population and the surrounding region impact the quality of life of residents.

### Data

Our dataset consists of a collection of various studies done by the CDC in 2018 that detail various characteristics of a particular city and its demographics, ranging from the percentage of people that are unemployed to the percentage of civilian noninstitutionalized population with a disability.

### Objective

Our objective is to analyze and document any causal relationships between features in the dataset, with an emphasis on per capita income (EP_PCI) and unemployment rate (EP_UNEMP).

\pagebreak

# Basic Analysis

## Question 1: SIMPLE REGRESSION

### Methods

**Data Cleaning & Preparation**

```{r echo=FALSE}
pander(quantile(svi_data$EP_UNEMP, p = c(0, 0.25, 0.5, 0.75, 1)) )
sum(svi_data$EP_UNEMP == -999)
# We seem to get some -999, which doesn't make sense in the context of estimated unemployment rates. In this column, we have 546 values / 72837 observations encoded as -999. 

pander(quantile(svi_data$EP_PCI, p = c(0, 0.25, 0.5, 0.75, 1)))
sum(svi_data$EP_PCI == -999)
# The EP_PCI column also has 481 values encoded as -999. 

# Change the -999 to NaNs
svi_data$EP_UNEMP[svi_data$EP_UNEMP == -999] <- NA
svi_data$EP_PCI[svi_data$EP_PCI == -999] <- NA

# Filter out the NaNs and store them in another dataset called "data".
data <- svi_data[complete.cases(svi_data$EP_PCI, svi_data$EP_UNEMP), ]
```

We want to create a regression model for `EP_PCI`, the estimated per capita income, based on the estimated proportion of unemployment, `EP_UNEMP`. We are predicting `EP_PCI` because it describes the *rate* of unemployment and is normalized against population, unlike `E_PCI`, which describes the estimate *count* the unemployed.

We will check the conditions for fitting a simple linear regression: linearity, homoscedasticity, independence, and normality.

1.  **Linearity** - Is there a linear relationship between our explanatory variable, `EP_UNEMP` and our response variable, `EP_PCI`?

```{r echo=FALSE}
plot(data$EP_UNEMP, data$EP_PCI, 
     xlab = 'Estimated Unemployment Rate', 
     ylab = 'Estimated Per Capita Income', 
     main = 'Trend in Estimated Per Capita Income Based on Estimated Unemp. Rate')
```

From our scatterplot, there appears to be a nonlinear negative trend between unemployment rate and estimated per capita income. As the estimated unemployment rate increases, the estimated per capita income exponentially decreases.

2.  **Homoscedasticity**: Would the variance for the estimated unemployment rate be constant if we were to use a linear model?

```{r echo=FALSE}
model <- lm(EP_PCI ~ EP_UNEMP, data = data)
res <- residuals(model)
plot(data$EP_UNEMP, res, 
     xlab = 'Estimated Unemployment Rate', 
     ylab = 'Estimated Per Capita Income', 
     main = 'Trend in Estimated Per Capita Income Based on Estimated Unemp. Rate')
abline(0,0, col = 'red')
```

The residuals do *not* have constant variance and so, the data is not homoscedastic.

3.  **Independence**: Because the residuals exhibit a clear pattern, independence may be violated.

4.  **Normality**: A QQ plot of our residuals shows our data deviates from the y = x line. Its slight curve upward suggests the distribution of our residuals are right-skewed.

```{r echo = FALSE}
qqnorm(res)
qqline(res, col = 'red')
```

### Analysis

```{r echo = FALSE}
# double log scale
data$log_unemp <- log(data$EP_UNEMP + 1e-6)
data$log_pci <- log(data$EP_PCI + 1e-6)

log_model <- lm(log_pci ~ log_unemp, data = data)

# change predictions back to the original scale
predictions <- predict(log_model, newdata = data.frame(log_unemp = data$log_unemp))
predictions <- exp(predictions)

# Plot the scatterplot
plot(data$log_unemp, data$EP_PCI,
     main = 'Estimated Per Capita Income as a Function of Log(Estimated Populated Rate)',
     xlab = 'Log(Estimated Population Rate)',
     ylab = 'Estimated Per Capita Income')

lines(data$log_unemp, predictions, col='red')

# Model evaluation
# evaluating log model
res <- residuals(log_model)
mse <- mean(res ** 2) # 0.201

# evaluating original model for interpretation purposes
mse_original <- mean((data$EP_PCI - predictions)^2)
```

With our log-transformed model, we have an MSE of about 0.201, which represents the averages squared difference between the actual values of the estimated per capita income and the predicted values. This number is pretty low, which indicates our model performed well. However, the MSE of our original model is 301,671,723, which means our model performed very poorly without the log transformation. 

### Conclusion
Based on these findings, the relationship between the estimated unemployment rate (EP_UNEMP) and the estimated per capita income (EP_PCI) do not meet the assumptions needed to fit a simple linear regression model without a transformation:
1. **Linearity:** The scatterplot shows a nonlinear, exponential relationship between EP_UNEMP and EP_PCI, which suggests a simple linear model is not the most effective.
2. **Homoscedasticity:** The residuals from the untransformed model show clear patterns and non-constant variance, which reaffirms the idea that our model does not perform well without a log transformation.
3. **Independence:** Similar to the point addressed in #2, the residual plots show clear patterns, which indicate a basic linear model is not suitable for this distribution. 
4. **Normality**: The QQ Plot demonstrates a slight right skew, which means that the residuals from a simple linear model are not normal, and so a transformation is necessary. 

## Question 2: Distribution Analysis

### Methods

To see the distributions of the `EP_UNEMP` and `EP_PCI`, we graphed each feature as a histogram.

```{r, echo=FALSE}
par(mfrow=c(1, 2))
hist(data$EP_UNEMP)

hist(data$EP_PCI)
```

Additionally, we compared these distributions to other features that we believe would be related to this linear model, such as the percentage of people who are uninsured (`EP_UNINSUR`) and the percentage of mobile homes in the city (`EP_MOBILE`).

```{r, echo=FALSE}
# remove Nans from data
data[data == -999] <- NA
par(mfrow=c(1, 2))
data <- data[complete.cases(data), ]
hist(data$EP_UNINSUR)
hist(data$EP_MOBILE)
```

### Analysis

We will conduct a **KS Analysis** to test whether the distribution of these features in our dataset are statistically similar.

-   **H0:** The distribution of both features are the same.

-   **H1:** The distribution of the features differ.

We meet the conditions to perform this test because these features are independent from one another and the data is continuous.

```{r}
# KS test
ks_test <- ks.test(data$EP_UNEMP, data$EP_PCI)
pander(ks_test)

ks_test <- ks.test(data$EP_UNEMP, data$EP_UNINSUR)
pander(ks_test)

ks_test <- ks.test(data$EP_UNEMP, data$EP_MOBILE)
pander(ks_test)

ks_test <- ks.test(data$EP_PCI, data$EP_UNINSUR)
pander(ks_test)

ks_test <- ks.test(data$EP_PCI, data$EP_MOBILE)
pander(ks_test)
```

### Conclusion

When looking at our visualizations for the features, it appears that are is no significant difference between their distributions, as they are all right-skewed. However, when performing a KS test, there appears to be a difference between the distributions, which suggests that there is a 

## Question 2: Distribution Analysis

### Methods
```{r}
library(dplyr)
filtered <- public_data %>%
  filter(
    hq_country == "United States of America", # filter for only locations in the US
    address_state != "", 
    address_city != "",
    address_state != 'DO NOT SEND LETTER', # doesn't have state or city
    address_state != 'England' # London, England, mistakenly recorded as a city, state in the US
  )

# Some states are spelled out by name; change to state abbreviation
filtered <- filtered %>%
  mutate(address_state = recode(
    address_state, 
    "Massachusetts" = "MA", 
    "Pennsylvania" = "PA",
    'California' = 'CA',
    'Wisconsin' = 'WI',
    'Virginia' = 'VA',
    'Texas' = 'TX',
    'Ca' = 'CA',
    'Utah' = 'UT',
    'Arizona' = 'AZ',
    'Chicago' = 'IL',
    'Illinois' = 'IL',
    'District of Columbia' = 'DC',
    'Washington' = 'WA',
    'Rhode Island' = 'RI',
    'Colorado' = 'CO',
    'COLORADO' = 'CO',
    'Michigan' = 'MI',
    'New York' = 'NY',
    'Ohio' = 'OH',
    'Delaware' = 'DE',
    'Georgia' = 'GA',
    'Minnesota' = 'MN',
    'Missouri' = 'MO',
    'Maryland' = 'MD'
  ))

filtered_df <- as.data.frame(filtered)
```
### Analysis
### Conclusion
