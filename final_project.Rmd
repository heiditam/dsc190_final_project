---
title: "final_project"
author: Student 1 & Student 2
output: pdf_document
date: "2024-12-01"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
public_data <- read.csv('./data/NA_HQ_public_data.csv')
svi_data <- read.csv('./data/SVI2018_US.csv')
us_cities <- read.csv('./data/uscities.csv')
library(pander)
```

# 0. Contribution Statement

## Student 1

Student 1 mostly worked on questions ...

## Student 2

Student 2 mostly worked on questions ...

\pagenumbering{arabic}

# Introduction

Cities provide a glimpse into the local population of an area and are reflective of the culture and lifestyles in the region in which they are located. However, not all cities are created equal, as different socieoeconomic factors within the population and the surrounding region impact the quality of life of residents.

### Data

Our primary dataset consists of a collection of various studies done by the CDC in 2018 that detail various characteristics of a particular city and its demographics, ranging from the percentage of people that are unemployed to the percentage of civilian noninstitutionalized population with a disability. There are 72836 entries.

We include a secondary dataset in our **Advanced Analysis** section of our report that consists of the climate action surveys of major international corporations and if they responded to the survey or not. There are two surveys collected (Water and Climate Change) between 2018 and 2020, inclusive.

### Objective

Our objective is to analyze and document any causal relationships between features in the dataset, with an emphasis on per capita income (`EP_PCI`) and unemployment rate (`EP_UNEMP`).

\pagebreak

# Basic Analysis

## **Question 1: SIMPLE REGRESSION** - Fit a regression line of the data predicting a cityâ€™s `EP_PCI` (estimated per capita income)* based on the estimated proportion of unemployment `EP_UNEMP`. How well does the regression line fit this relationship?

### Methods

**Data Cleaning & Preparation**

```{r echo=FALSE}
pander(quantile(svi_data$EP_UNEMP, p = c(0, 0.25, 0.5, 0.75, 1)) )
sum(svi_data$EP_UNEMP == -999)
# We seem to get some -999, which doesn't make sense in the context of estimated unemployment rates. In this column, we have 546 values / 72837 observations encoded as -999. 

pander(quantile(svi_data$EP_PCI, p = c(0, 0.25, 0.5, 0.75, 1)))
sum(svi_data$EP_PCI == -999)
# The EP_PCI column also has 481 values encoded as -999. 

# Change the -999 to NaNs
svi_data$EP_UNEMP[svi_data$EP_UNEMP == -999] <- NA
svi_data$EP_PCI[svi_data$EP_PCI == -999] <- NA

# Filter out the NaNs and store them in another dataset called "data".
data <- svi_data[complete.cases(svi_data$EP_PCI, svi_data$EP_UNEMP), ]
```

We want to create a regression model for `EP_PCI`, the estimated per capita income, based on the estimated proportion of unemployment, `EP_UNEMP`. We are predicting `EP_PCI` because it describes the *rate* of unemployment and is normalized against population, unlike `E_PCI`, which describes the estimate *count* the unemployed.

We will check the conditions for fitting a simple linear regression: linearity, homoscedasticity, independence, and normality.

1.  **Linearity** - Is there a linear relationship between our explanatory variable, `EP_UNEMP` and our response variable, `EP_PCI`?

```{r echo=FALSE}
plot(data$EP_UNEMP, data$EP_PCI, 
     xlab = 'Estimated Unemployment Rate', 
     ylab = 'Estimated Per Capita Income', 
     main = 'Trend in Estimated Per Capita Income Based on Estimated Unemp. Rate')
```

From our scatterplot, there appears to be a nonlinear negative trend between unemployment rate and estimated per capita income. As the estimated unemployment rate increases, the estimated per capita income exponentially decreases.

2.  **Homoscedasticity**: Would the variance for the estimated unemployment rate be constant if we were to use a linear model?

```{r echo=FALSE}
model <- lm(EP_PCI ~ EP_UNEMP, data = data)
res <- residuals(model)
plot(data$EP_UNEMP, res, 
     xlab = 'Estimated Unemployment Rate', 
     ylab = 'Estimated Per Capita Income', 
     main = 'Trend in Estimated Per Capita Income Based on Estimated Unemp. Rate')
abline(0,0, col = 'red')
```

The residuals do *not* have constant variance and so, the data is not homoscedastic.

3.  **Independence**: Because the residuals exhibit a clear pattern, independence may be violated.

4.  **Normality**: A QQ plot of our residuals shows our data deviates from the y = x line. Its slight curve upward suggests the distribution of our residuals are right-skewed.

```{r echo = FALSE}
qqnorm(res)
qqline(res, col = 'red')
```

### Analysis
To transform the data, we will take the log of `EP_UNEMP` and `EP_PCI` because log transformations are often used to stabilize variance and help make data more suitable for regression. 
```{r echo = FALSE}
# double log scale
data$log_unemp <- log(data$EP_UNEMP + 1e-6)
data$log_pci <- log(data$EP_PCI + 1e-6)

log_model <- lm(log_pci ~ log_unemp, data = data)

# change predictions back to the original scale
predictions <- predict(log_model, newdata = data.frame(log_unemp = data$log_unemp))
predictions <- exp(predictions)

# Plot the scatterplot
plot(data$log_unemp, data$EP_PCI,
     main = 'Estimated Per Capita Income as a Function of Log(Estimated Populated Rate)',
     xlab = 'Log(Estimated Population Rate)',
     ylab = 'Estimated Per Capita Income')

lines(data$log_unemp, predictions, col='red')

# Model evaluation
# evaluating log model
res <- residuals(log_model)
mse <- mean(res ** 2) # 0.201

# evaluating original model for interpretation purposes
mse_original <- mean((data$EP_PCI - predictions)^2)
```

With our log-transformed model, we have an MSE of about 0.201, which represents the averages squared difference between the actual values of the estimated per capita income and the predicted values. This number is pretty low, which indicates our model performed well. However, the MSE of our original model is 301,671,723, which means our model performed very poorly without the log transformation. 

### Conclusion
Based on these findings, the relationship between the estimated unemployment rate (EP_UNEMP) and the estimated per capita income (EP_PCI) do not meet the assumptions needed to fit a simple linear regression model without a transformation:

1. **Linearity:** The scatterplot shows a nonlinear, exponential relationship between EP_UNEMP and EP_PCI, which suggests a simple linear model is not the most effective.

2. **Homoscedasticity:** The residuals from the untransformed model show clear patterns and non-constant variance, which reaffirms the idea that our model does not perform well without a log transformation.

3. **Independence:** Similar to the point addressed in #2, the residual plots show clear patterns, which indicate a basic linear model is not suitable for this distribution. 

4. **Normality**: The QQ Plot demonstrates a slight right skew, which means that the residuals from a simple linear model are not normal, and so a transformation is necessary. 

## **Question 2: Distribution Analysis** - How do the distributions of `EP_PCI` and `EP_UNEMP` compare to one another and among other features?

### Methods

To see the distributions of the `EP_UNEMP` and `EP_PCI`, we graphed each feature as a histogram.

```{r, echo=FALSE}
par(mfrow=c(1, 2))
hist(data$EP_UNEMP)

hist(data$EP_PCI)
```

Additionally, we compared these distributions to other features that we believe would be related to this linear model, such as the percentage of people who are uninsured (`EP_UNINSUR`) and the percentage of mobile homes in the city (`EP_MOBILE`).

```{r, echo=FALSE}
# remove Nans from data
data[data == -999] <- NA
data <- data[complete.cases(data), ]

par(mfrow=c(1, 2))

# plot histograms of EP_UNINSUR and EP_MOBILE
hist(data$EP_UNINSUR)
hist(data$EP_MOBILE)
```

### Analysis

We will conduct a **KS Analysis** to test whether the distribution of these features in our dataset are statistically similar.

-   **H0:** The distribution of both features are the same.

-   **H1:** The distribution of the features differ.

We meet the conditions to perform this test because these features are independent from one another and the data is continuous.

```{r, echo=FALSE}
# KS test
ks_test <- ks.test(data$EP_UNEMP, data$EP_PCI, exact=TRUE)
pander(ks_test)

ks_test <- ks.test(data$EP_UNEMP, data$EP_UNINSUR, exact=TRUE)
pander(ks_test)

ks_test <- ks.test(data$EP_UNEMP, data$EP_MOBILE, exact=TRUE)
pander(ks_test)

ks_test <- ks.test(data$EP_PCI, data$EP_UNINSUR, exact=TRUE)
pander(ks_test)

ks_test <- ks.test(data$EP_PCI, data$EP_MOBILE, exact=TRUE)
pander(ks_test)
```

### Conclusion

When looking at our visualizations for the features, it appears that are is no significant difference between their distributions, as they are all right-skewed. However, our results from the KS test reflect the opposite conclusion, as the test statistics for each test are less than the test statistic at alpha = 0.05. As a result, we cannot conclude if the distributions of these features are statistically similar, and therefore we cannot conclude that they affect the value of `EP_UNEMP`. 

## **Question 3: Hypothesis Testing** - Do cities in states with higher percentages of `EP_PCI` (estimated per capita income) have significantly fewer climate action responses compared to those with lower percentages?

### Methods
H0: There is no significant difference between the number of climate action responses in states with higher percentages of EP_PCI compared to states with lower percentages. 
H1: States with higher percentages of EP_PCI have significantly _fewer_ climate action responses compared to states with lower percentages of EP_PCI. 

```{r echo = FALSE}
library(dplyr)
filtered <- public_data %>%
  filter(
    hq_country == "United States of America", # filter for only locations in the US
    address_state != "", 
    address_city != "",
    address_state != 'DO NOT SEND LETTER', # doesn't have state or city
    address_state != 'England' # London, England, mistakenly recorded as a city, state in the US
  )

# Some states are spelled out by name; change to state abbreviation
filtered <- filtered %>%
  mutate(address_state = recode(
    address_state, 
    "Massachusetts" = "MA", 
    "Pennsylvania" = "PA",
    'California' = 'CA',
    'Wisconsin' = 'WI',
    'Virginia' = 'VA',
    'Texas' = 'TX',
    'Ca' = 'CA',
    'Utah' = 'UT',
    'Arizona' = 'AZ',
    'Chicago' = 'IL',
    'Illinois' = 'IL',
    'District of Columbia' = 'DC',
    'Washington' = 'WA',
    'Rhode Island' = 'RI',
    'Colorado' = 'CO',
    'COLORADO' = 'CO',
    'Michigan' = 'MI',
    'New York' = 'NY',
    'Ohio' = 'OH',
    'Delaware' = 'DE',
    'Georgia' = 'GA',
    'Minnesota' = 'MN',
    'Missouri' = 'MO',
    'Maryland' = 'MD'
  ))

filtered_df <- as.data.frame(filtered)

# Merge the data filtered from the SVI DataFrame (shows the the socieoeconomic vulnerability index for various cities in the US) with the public city data. 
merged_df <- merge(
  x = filtered_df[, c('theme', 'address_state')],
  y = data[, c('ST_ABBR', 'EP_PCI')],
  by.x = 'address_state',
  by.y = 'ST_ABBR',
  all = FALSE
)
```
We have just created a DataFrame that shows the state, whether they took a climate or water action, and the EP_PCI (estimated per capita income) for each city recorded. 
NOTE: Cities are not included in our merged DataFrame since we are just interested in the cities' states. 

### Analysis
```{r echo = FALSE}
median_pci <- median(merged_df$EP_PCI, na.rm = TRUE)

# Create a column that says whether the city's EP_PCI is higher or lower compared to the median value
merged_df <- merged_df %>%
  mutate(pci_status = ifelse(EP_PCI > median_pci, 'Higher', 'Lower'))

# Our data currently contains climate change and water action data. We will filter for climate action data since it is what we care about more. 
climate_data <- merged_df %>%
  filter(theme == 'Climate Change')

# Create a table that summarizes the number of actions taken per each location that are related to climate change. 
summary_df <- climate_data %>%
  group_by(address_state, pci_status) %>%
  summarize(
    count = n(),
    .groups = 'drop'
  )
```
The summary_df keeps track of the number of climate change-related actions taken for various cities grouped by state and PCI status (either higher or lower than the median value). 

```{r echo = FALSE}
# Is the distribution of counts of climate action normally distributed for values higher than the median?
higher_counts <- summary_df$count[summary_df$pci_status == "Higher"]
shapiro.test(higher_counts)

lower_counts <- summary_df$count[summary_df$pci_status == "Lower"]
shapiro.test(lower_counts)
```
Neither of these groups are normally distributed, so we need to use a Mann-Whitney U Test for comparing the mean counts of climate action for the groups with EP_PCI lower vs. higher than the median EP_PCI. 

```{r echo = FALSE}
wilcox.test(count ~ pci_status, data = summary_df, alternative = 'less')
```
Because (p = 0.3852) > (alpha = 0.05), we fail to reject the null hypothesis. Cities in states with higher percentages of EP_PCI _do not_ have significantly fewer climate action responses compared to those with lower percentages. 

### Conclusion
We merged the SVI Data with the city data and performed data cleaning to keep track of the number of cities with an EP_PCI status higher or lower than the median EP_PCI status. Since Shapiro-Wilk tests showed that our data for each group - Higher and Lower - were both not normally distributed, we had to use a Mann Whitney U Test (aka Wilcoxon Rank Sum Test) to compare the two groups since it is a non-parametric statistical test. Since we ended with a p-value of 0.3852 > 0.05, we fail to reject the null hypothesis. This means that cities in states with higher percentages of EP_PCI _do not_ have significantly fewer climate action responses compared to those with lower percentages. 

## **Question 4: Correlation Analysis** - Is there a significant correlation between the `EP_PCI` and `EP_UNEMP`? How strong is the relationship, and what does it suggest about the role of unemployment in estimated per capita income?

### Methods

To understand the correlation between these two features, we calculate the covariance for the features.

```{r, echo=FALSE}

correlation <- cor(data$EP_PCI, data$EP_UNEMP, use = "complete.obs", method = "pearson")
print(correlation)

```

### Analysis

Next, we test the significance of their correlation with the following hypotheses:

-   **H0:** The correlation between `EP_PCI` and `EP_UNEMP` is equal to zero.

-   **H1:** The correlation between `EP_PCI` and `EP_UNEMP` is not equal to zero.

```{r, echo=FALSE}
cor_test <- cor.test(data$EP_PCI, data$EP_UNEMP, method = "pearson")
pander(cor_test)
```

The correlation coefficient between `EP_PCI` and `EP_UNEMP` is **-0.4062332**, which signifies a somewhat strong negative correlation between the two features. After performing a significance test on this coefficient, it is clear that it is statistically significant, as the test statistic is **-119.4** and the p-value is **0**. The negative sign in the test statistic shows that the correlation between these two features is negative, with its large magnitude reinforcing this relationship. Additionally, the p-value tells us to reject the null hypothesis, providing evidence that the correlation between the two feature is not equal to zero. 

### Conclusion

We can conclude that there is a statistically significant negative correlation between `EP_PCI` and `EP_UNEMP`, which is supported by the significance test we performed on the calculated correlation coefficient. This shows us that as unemployment increases within a city's population, the city's per capita income is expected to decrease. Additionally, the relationship between these two features is rather strong, as the magnitude of the correlation coefficient is a signiificant magnitude below zero.

## **Advanced Analysis: Multiple Regression** - Fit a regression line of the data predicting a cityâ€™s `EP_PCI` (estimated per capita income) based on the estimated proportion of unemployment `EP_UNEMP`, city population, and city density. How well does the regression line fit this relationship?

### Methods

We used XGBoost to optimize our prediction of EP_PCI, the estimated per capita income. 

### Data Preparation

To fit a regression line as specified above, we will need the following variables from the `data` dataset:

* Dependent Variable: EP_PCI - estimated per capita income

* Independent Variables: 

    * `E_NOHSDP` - percentage of people without a high school diploma (age 25+)
    * `EP_DISAB` - percentage of civilian non-institutionalized population who are disabled
    * `EP_MINRTY` - percentage of minority people
We choose these features because education is one of the strongest predictors of income, and we would expect people without a high school diploma to have fewer opportunities for job growth and thus, make a lower income than those with a higher degree. Disability status may also affect one's ability to work full time, leading them to make lower incomes. Cities with a higher percentage of disabled individuals may have a lower per capita income. Thirdly, minority populations may deal with socioeconomic disparities and restricted opportunities to education, wealth, and jobs. We also expect there to be a relationship between the proportion of minorities and income. Perhaps cities with a higher proportion of minorities may also have a lower per capita income. 

```{r echo = FALSE}
boxplot(data$EP_PCI, horizontal = TRUE, xlab = "Per Capita Income (EP_PCI)")
```
As you can see, there are many outliers in our data, so we removed data points that were below the 25th percentile or above the 75th percentile, per the IQR Rule. 

```{r echo = FALSE}
library(xgboost)
library(caret)

orig_features <- data[, c('EP_NOHSDP', 'EP_DISABL', 'EP_MINRTY')]
orig_target <- data$EP_PCI

Q1 <- quantile(orig_target, 0.25)
Q3 <- quantile(orig_target, 0.75)
IQR <- Q3 - Q1

lower_bound <- Q1 - 1.5 * IQR
upper_bound <- Q3 + 1.5 * IQR

data_filtered <- data[orig_target >= lower_bound & orig_target <= upper_bound, ]

# Update our features & target! 
features <- data_filtered[, c('EP_NOHSDP', 'EP_DISABL', 'EP_MINRTY')]
target <- data_filtered$EP_PCI
```
### Model Training
With the aid of the package Caret, we used 80% of the original dataset for training and the remaining 20% for testing. Our model used the objective function of regression with mean squared error and our evaluation metric was RMSE for better interpretability. 
``` {r echo = FALSE}
# Split into train + test
set.seed(123)
train_index <- createDataPartition(target, p = 0.8, list = FALSE)
train_features <- features[train_index, ]
train_target <- target[train_index]
test_features <- features[-train_index, ]
test_target <- target[-train_index]

# convert to matrices
train_matrix <- as.matrix(train_features)
test_matrix <- as.matrix(test_features)

# DMatrix objects
dtrain <- xgb.DMatrix(data = train_matrix, label = train_target)
dtest <- xgb.DMatrix(data = test_matrix, label = test_target)

# hyperparameters
params <- list(
    objective = "reg:squarederror",
    eval_metric = "rmse",
    eta = 0.1,
    max_depth = 6,
    subsample = 0.8,
    colsample_bytree = 0.8
)
```
The hyperparameters we used were learning rate = 0.1, max_depth = 6, subsample = 0.8 (80% of the samples used per boosting round to prevent overfitting), and colsample_bytree = 0.8 (80% of the features used per tree).

``` {r echo = FALSE}
# Train the model
xgb_model <- xgb.train(
    params = params,
    data = dtrain,
    nrounds = 500,
    watchlist = list(train = dtrain, test = dtest),
    early_stopping_rounds = 10,
    verbose = 1
)

# PREDICTIONS
predictions <- predict(xgb_model, test_matrix)

# MODEL EVALUATIONS
# RMSE
rmse <- sqrt(mean((test_target - predictions) ^ 2))
cat("RMSE:", rmse, "\n")

# MAE
mae <- mean(abs(test_target - predictions))
cat("MAE:", mae, "\n")

# FEATURE IMPORTANCE
importance <- xgb.importance(feature_names = colnames(train_matrix), model = xgb_model)
xgb.plot.importance(importance)
```
Our multiple linear regression model fits the line EP_PCI-hat = 42000 - 1525 * EP_UNEMP -0.1309 * E_TOTPOP + 0.115 * city_density. Here is how we would interpret our model: 
* **Slope of EP_UNEMP**: For every 1% increase in unemployed people, we would expect income to decrease by $1,525 per capita. 
* **Slope of E_TOTPOP**: For every additional person in the total population, we would expect income to decrease by about $0.1309 per capita.
* **Slope of city_density**: For every additional person per square mile, we would expect income to increase by about $0.115 per capita. 
* **Intercept**: All factors held constant, we would expect the income to be $4,200 per capita if the unemployment rate is 0, total population is 0, and city density is 0. However, it is important to note this involves extrapolation and is inappropriate to infer in this context. 

### Analysis
```{r echo = FALSE}
plot(adv_model)
```

A multiple linear regression model is probably also not the best choice for the model because the residuals vs. fitted scatterplot show a clear pattern trending upward as the fitted values increase. Additionally, in the QQ Plot, the residuals do not always fall approximately along the diagonal and indicate normality; instead, after the theoretical quantile of 2,the the residuals curve upward, which demonstrate a distribution of the residuals is right-skewed. In the scale-location graph, the residuals do not appear to be evenly spaced, and in the residuals vs leverage graph, it is evident that some residuals are associated with a very high leverage. 

```{r echo = FALSE}

```

### Conclusion
```{r echo = FALSE}
predictions <- predict(adv_model, newdata = clean_advanced_df)
residuals <- clean_advanced_df$EP_PCI - predictions
rmse <- sqrt(mean(residuals ^ 2))
rmse
```
With an RMSE of 15,289.38, our multiple linear regression model is not very predictive of our data. It is better to use a different type of model. 

## Conclusion & Discussion

In conclusion, our analysis of the causal relationship between per capita income (`EP_PCI`) and unemployment rate (`EP_UNEMP`) in the socioeconomic vulnerability index dataset reveal that there is a strong negative correlation between them, though a linear regression may not be the best model to capture the nuances of their relationship. Additionally, the distributions of these features appear to be similar, but there is no statistical evidence to support this. In our advanced analysis, we attempt to fit a multiple linear regression with the addition of new features that describe the population distribution and density of a city.

One limititation that we noticed with our data was missing data in the socieoeconomic vulnerability index dataset. Although we removed missing data, the resulting data could underestimate or overestimate certain features of the dataset, which inhibits our ability to make accurate calculations. 
